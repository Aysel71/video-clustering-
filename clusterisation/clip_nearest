#!/usr/bin/env python3
"""
COMPLETE OPTIMIZED ADAPTIVE SELECTOR WITH FIXES
===============================================

Fixes:
1. Safe cloud upload (fixed filename errors)
2. Retry mechanism for reliability
3. Fallback to local storage
4. Improved error handling
5. Detailed progress and logging
"""

import os
import json
import logging
import cv2
import boto3
import yt_dlp
import torch
import clip
import random
import numpy as np
import requests
import time
import re
from PIL import Image
from pathlib import Path
from datetime import datetime
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.metrics.pairwise import cosine_similarity, cosine_distances
from datasets import load_dataset
from collections import defaultdict
from typing import List, Dict, Tuple, Optional
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

os.environ['TOKENIZERS_PARALLELISM'] = 'false'

def setup_logging():
    """Setup logging"""
    log_format = '%(asctime)s - %(levelname)s - %(message)s'
    Path('logs').mkdir(exist_ok=True)
    log_filename = f"logs/adaptive_selection_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    
    logging.basicConfig(
        level=logging.INFO,
        format=log_format,
        handlers=[
            logging.FileHandler(log_filename, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

logger = setup_logging()

class OptimizedFrameSelector:
    """Optimized selector with fixed cloud upload"""
    
    def __init__(self, bucket_name: str = "videoresearch"):
        self.bucket_name = bucket_name
        self.frame_interval = 16
        self.max_frames = 8
        self.min_clusters = 2
        self.max_clusters = 6
        
        # Cloud paths
        self.cloud_frames_prefix = "extracted_frames/"
        self.cloud_selected_prefix = "selected_frames_adaptive/"
        
        # API configuration
        self.FIREWORKS_API_KEY = "key"
        self.fireworks_url = "https://api.fireworks.ai/inference/v1/chat/completions"
        self.model_name = "fireworks/qwen2p5-vl-32b-instruct"
        
        self.backup_models = [
            "fireworks/qwen2-vl-7b-instruct",
            "fireworks/llava-v1p6-34b-instruct"
        ]
        
        self.categories = [
            'Action Recognition', 'Action Reasoning', 'Attribute Perception',
            'Counting Problem', 'OCR Problems', 'Object Recognition',
            'Spatial Perception', 'Spatial Reasoning', 'Temporal Perception',
            'Temporal Reasoning'
        ]
        
        self.answer_choices = ['A', 'B', 'C', 'D', 'E']
        
        self._setup_system()
        
        # Statistics with save information
        self.stats = {
            'start_time': datetime.now(),
            
            # Processing attempts
            'attempted': {
                'total_videos': 0,
                'by_category': defaultdict(int)
            },
            
            # Successfully processed
            'successfully_processed': {
                'total_videos': 0,
                'correct_answers': 0,
                'by_category': defaultdict(lambda: {'correct': 0, 'total': 0})
            },
            
            # Errors by type
            'errors': {
                'download_failed': 0,
                'frame_extraction_failed': 0,
                'api_request_failed': 0,
                'answer_extraction_failed': 0,
                'cloud_upload_failed': 0,
                'other_errors': 0,
                'by_category': defaultdict(lambda: {
                    'download_failed': 0,
                    'frame_extraction_failed': 0,
                    'api_request_failed': 0,
                    'answer_extraction_failed': 0,
                    'cloud_upload_failed': 0,
                    'other_errors': 0
                })
            },
            
            # Frame extraction statistics
            'frame_extraction': {
                'total_extractions': 0,
                'successful_uploads': 0,
                'partial_uploads': 0,
                'failed_uploads': 0,
                'total_frames_extracted': 0
            }
        }
    
    def _setup_system(self):
        """System setup"""
        logger.info("Initializing optimized frame selector")
        
        self._setup_device()
        self._setup_cloud_storage()
        self._load_clip_model()
        self._setup_ytdlp()
        self._create_directories()
        self._load_dataset()
        self._scan_available_videos()
        
        logger.info("System initialized")
    
    def _setup_device(self):
        """Device setup"""
        torch.set_default_dtype(torch.float32)
        
        if torch.backends.mps.is_available():
            self.device = "mps"
            logger.info("Using Apple Silicon GPU (MPS)")
        elif torch.cuda.is_available():
            self.device = "cuda"
            logger.info("Using NVIDIA GPU")
        else:
            self.device = "cpu"
            logger.info("Using CPU")
    
    def _setup_cloud_storage(self):
        """Setup Yandex Cloud Storage"""
        access_key = os.getenv('YANDEX_ACCESS_KEY') or "key"
        secret_key = os.getenv('YANDEX_SECRET_KEY') or "key"
        
        self.s3_client = boto3.client(
            's3',
            endpoint_url='https://storage.yandexcloud.net',
            aws_access_key_id=access_key,
            aws_secret_access_key=secret_key
        )
        
        logger.info("Yandex Cloud connection established")
    
    def _load_clip_model(self):
        """Load CLIP model"""
        logger.info("Loading CLIP model...")
        self.clip_model, self.clip_preprocess = clip.load("ViT-B/32", device=self.device)
        self.clip_model = self.clip_model.float()
        self.clip_model.eval()
        logger.info("CLIP model loaded")
    
    def _setup_ytdlp(self):
        """Setup yt-dlp"""
        user_agents = [
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        ]
        
        self.ydl_opts = {
            'format': 'best[height<=720]/best',
            'outtmpl': '%(id)s.%(ext)s',
            'writeinfojson': True,
            'ignoreerrors': True,
            'quiet': True,
            'no_warnings': True,
            'http_headers': {
                'User-Agent': random.choice(user_agents)
            }
        }
    
    def _create_directories(self):
        """Create directories"""
        directories = [
            'temp_videos', 'temp_frames', 'adaptive_results', 
            'selected_frames_adaptive', 'logs', 'downloaded_frames'
        ]
        for directory in directories:
            Path(directory).mkdir(exist_ok=True)
    
    def _load_dataset(self):
        """Load dataset with questions"""
        logger.info("Loading dataset...")
        
        self.dataset = load_dataset("facebook/PLM-Video-Auto", "yt1b_mcqa", split="train")
        
        self.dataset_index = {}
        for sample in self.dataset:
            if sample['category'] in self.categories:
                key = (sample['video_id'], sample['category'])
                self.dataset_index[key] = sample
        
        logger.info(f"Loaded {len(self.dataset_index)} questions")
    
    def _scan_available_videos(self):
        """Scan available videos"""
        logger.info("Scanning available videos...")
        
        self.available_videos = defaultdict(list)
        
        for category in self.categories:
            try:
                prefix = f"frames/{category}/"
                response = self.s3_client.list_objects_v2(
                    Bucket=self.bucket_name,
                    Prefix=prefix,
                    Delimiter='/'
                )
                
                if 'CommonPrefixes' in response:
                    for obj in response['CommonPrefixes']:
                        video_id = obj['Prefix'].split('/')[-2]
                        
                        key = (video_id, category)
                        if key in self.dataset_index:
                            self.available_videos[category].append(video_id)
                
                logger.info(f"{category}: {len(self.available_videos[category])} videos")
                
            except Exception as e:
                logger.warning(f"Error scanning {category}: {e}")
        
        total_videos = sum(len(videos) for videos in self.available_videos.values())
        logger.info(f"Total available {total_videos} videos with questions")

    def check_frames_in_cloud(self, video_id: str) -> bool:
        """Check if frames exist in cloud"""
        try:
            # Check safe name as well
            safe_video_id = re.sub(r'^[-_]+', '', video_id)
            safe_video_id = re.sub(r'[^a-zA-Z0-9_-]', '_', safe_video_id)
            safe_video_id = safe_video_id[:50]
            
            for vid in [video_id, safe_video_id]:
                cloud_path = f"{self.cloud_frames_prefix}{vid}/"
                response = self.s3_client.list_objects_v2(
                    Bucket=self.bucket_name,
                    Prefix=cloud_path,
                    MaxKeys=1
                )
                
                if 'Contents' in response and len(response['Contents']) > 0:
                    logger.info(f"Frames for {video_id} found in cloud: {cloud_path}")
                    return True
            
            logger.info(f"Frames for {video_id} NOT found in cloud")
            return False
            
        except Exception as e:
            logger.warning(f"Error checking cloud for {video_id}: {e}")
            return False

    def download_frames_from_cloud(self, video_id: str) -> List[Dict]:
        """Download frames and metadata from cloud"""
        try:
            logger.info(f"Downloading frames {video_id} from cloud...")
            
            # Try original and safe name
            safe_video_id = re.sub(r'^[-_]+', '', video_id)
            safe_video_id = re.sub(r'[^a-zA-Z0-9_-]', '_', safe_video_id)
            safe_video_id = safe_video_id[:50]
            
            metadata_found = False
            metadata = None
            
            for vid in [video_id, safe_video_id]:
                try:
                    metadata_key = f"{self.cloud_frames_prefix}{vid}/metadata.json"
                    response = self.s3_client.get_object(Bucket=self.bucket_name, Key=metadata_key)
                    metadata = json.loads(response['Body'].read().decode('utf-8'))
                    metadata_found = True
                    logger.info(f"Metadata found for ID: {vid}")
                    break
                except Exception:
                    continue
            
            if not metadata_found:
                raise Exception("Metadata not found")
            
            # Create local folder
            local_frames_dir = Path('downloaded_frames') / video_id
            local_frames_dir.mkdir(parents=True, exist_ok=True)
            
            frames = []
            cloud_base_path = f"{self.cloud_frames_prefix}{vid}/"
            
            for frame_info in metadata['frames']:
                # Download each frame
                cloud_frame_key = f"{cloud_base_path}{frame_info['filename']}"
                local_frame_path = local_frames_dir / frame_info['filename']
                
                try:
                    self.s3_client.download_file(
                        self.bucket_name, 
                        cloud_frame_key, 
                        str(local_frame_path)
                    )
                    
                    # Restore frame structure
                    frame = {
                        'index': frame_info['index'],
                        'frame_number': frame_info['frame_number'],
                        'timestamp': frame_info['timestamp'],
                        'filename': frame_info['filename'],
                        'path': str(local_frame_path),
                        'embedding': np.array(frame_info['embedding'])
                    }
                    
                    frames.append(frame)
                    
                except Exception as frame_error:
                    logger.warning(f"Error downloading frame {frame_info['filename']}: {frame_error}")
                    continue
            
            logger.info(f"Downloaded {len(frames)} frames from cloud for {video_id}")
            self.stats['frame_reuse']['reused_from_cloud'] += 1
            
            return frames
            
        except Exception as e:
            logger.error(f"Error downloading frames from cloud for {video_id}: {e}")
            raise

    def upload_frames_to_cloud(self, frames: List[Dict], video_id: str) -> str:
        """FIXED cloud upload"""
        try:
            # FIX 1: Safe name for cloud
            safe_video_id = re.sub(r'^[-_]+', '', video_id)  # Remove leading dashes
            safe_video_id = re.sub(r'[^a-zA-Z0-9_-]', '_', safe_video_id)  # Replace special chars
            safe_video_id = safe_video_id[:50]  # Limit length
            
            if not safe_video_id:  # If name is empty after cleaning
                safe_video_id = f"video_{hash(video_id) % 100000}"
            
            cloud_path = f"{self.cloud_frames_prefix}{safe_video_id}/"
            logger.info(f"Uploading {len(frames)} frames to cloud: {cloud_path}")
            logger.info(f"Original ID: {video_id} → Safe ID: {safe_video_id}")
            
            uploaded_frames = []
            failed_uploads = 0
            
            # FIX 2: Upload with retry and better error handling
            for i, frame in enumerate(frames):
                try:
                    cloud_key = f"{cloud_path}{frame['filename']}"
                    
                    # FIX 3: Check file existence
                    if not os.path.exists(frame['path']):
                        logger.warning(f"File not found: {frame['path']}")
                        failed_uploads += 1
                        continue
                    
                    # FIX 4: Check file size
                    file_size = os.path.getsize(frame['path'])
                    if file_size == 0:
                        logger.warning(f"Empty file: {frame['filename']}")
                        failed_uploads += 1
                        continue
                    
                    if file_size > 10 * 1024 * 1024:  # 10MB limit
                        logger.warning(f"File too large: {frame['filename']} ({file_size/1024/1024:.1f}MB)")
                        failed_uploads += 1
                        continue
                    
                    # FIX 5: Retry mechanism
                    upload_success = False
                    for attempt in range(3):
                        try:
                            # Use more reliable upload method
                            with open(frame['path'], 'rb') as f:
                                self.s3_client.put_object(
                                    Bucket=self.bucket_name,
                                    Key=cloud_key,
                                    Body=f.read(),
                                    ContentType='image/jpeg',
                                    Metadata={
                                        'original_video_id': video_id,
                                        'frame_number': str(frame['frame_number']),
                                        'timestamp': str(frame['timestamp'])
                                    }
                                )
                            upload_success = True
                            break
                            
                        except Exception as upload_error:
                            logger.warning(f"Attempt {attempt + 1}/3 failed for {frame['filename']}: {upload_error}")
                            if attempt < 2:  # Not last attempt
                                time.sleep(2 ** attempt)  # Exponential backoff
                    
                    if not upload_success:
                        failed_uploads += 1
                        logger.error(f"Failed to upload {frame['filename']} after 3 attempts")
                        continue
                    
                    # FIX 6: Save metadata only for successfully uploaded
                    frame_metadata = {
                        'index': int(frame['index']),
                        'frame_number': int(frame['frame_number']),
                        'timestamp': float(frame['timestamp']),
                        'filename': frame['filename'],
                        'embedding': frame['embedding'].tolist(),
                        'file_size': file_size
                    }
                    
                    uploaded_frames.append(frame_metadata)
                    
                    # Progress every 100 frames
                    if (i + 1) % 100 == 0:
                        success_rate = ((i + 1 - failed_uploads) / (i + 1)) * 100
                        logger.info(f"Progress: {i + 1}/{len(frames)} ({success_rate:.1f}% success)")
                        
                except Exception as e:
                    logger.warning(f"General error for frame {i} ({frame.get('filename', 'unknown')}): {e}")
                    failed_uploads += 1
                    continue
            
            # FIX 7: More tolerant result check
            success_rate = (len(uploaded_frames) / len(frames)) * 100
            
            if len(uploaded_frames) == 0:
                raise Exception("Failed to upload any frames")
            
            if success_rate < 50:  # Less than 50% is a problem
                logger.warning(f"Low success rate: {success_rate:.1f}%")
                self.stats['frame_extraction']['partial_uploads'] += 1
            else:
                self.stats['frame_extraction']['successful_uploads'] += 1
            
            # FIX 8: Extended metadata
            metadata = {
                'video_id': safe_video_id,
                'original_video_id': video_id,
                'total_frames_attempted': len(frames),
                'total_frames_uploaded': len(uploaded_frames),
                'failed_uploads': failed_uploads,
                'success_rate_percent': success_rate,
                'frame_interval': getattr(self, 'frame_interval', 16),
                'extraction_timestamp': datetime.now().isoformat(),
                'clip_model': 'ViT-B/32',
                'upload_notes': f"Uploaded {len(uploaded_frames)}/{len(frames)} frames successfully",
                'frames': uploaded_frames
            }
            
            # FIX 9: Safe metadata upload
            try:
                metadata_key = f"{cloud_path}metadata.json"
                metadata_json = json.dumps(metadata, ensure_ascii=False, indent=2)
                
                self.s3_client.put_object(
                    Bucket=self.bucket_name,
                    Key=metadata_key,
                    Body=metadata_json.encode('utf-8'),
                    ContentType='application/json'
                )
                
                logger.info(f"Metadata saved: {metadata_key}")
                
            except Exception as meta_error:
                logger.error(f"Error saving metadata: {meta_error}")
                # But don't stop the whole process
            
            # FINAL RESULT
            logger.info(f"UPLOAD COMPLETED:")
            logger.info(f"  Uploaded: {len(uploaded_frames)}/{len(frames)} ({success_rate:.1f}%)")
            logger.info(f"  Failures: {failed_uploads}")
            logger.info(f"  Cloud path: {cloud_path}")
            
            return cloud_path
            
        except Exception as e:
            logger.error(f"Critical cloud upload error: {e}")
            self.stats['frame_extraction']['failed_uploads'] += 1
            # FIX 10: Even if cloud doesn't work, don't stop the whole process
            logger.info("Continuing without cloud save")
            
            # Return local path
            return f"local_fallback/{video_id}/"

    def get_question_embedding(self, question_text: str) -> np.ndarray:
        """Get CLIP embedding of question text"""
        try:
            clean_question = re.sub(r'[A-E]\)\s*', '', question_text)
            clean_question = re.sub(r'\n+', ' ', clean_question)
            clean_question = clean_question.strip()
            
            with torch.no_grad():
                text_tokens = clip.tokenize([clean_question]).to(self.device)
                text_features = self.clip_model.encode_text(text_tokens)
                text_embedding = text_features.float().cpu().numpy().flatten()
            
            return text_embedding
            
        except Exception as e:
            logger.error(f"Error getting question embedding: {e}")
            return None

    def download_video(self, video_id: str) -> str:
        """Download video"""
        try:
            video_url = f"https://www.youtube.com/watch?v={video_id}"
            logger.info(f"Downloading video: {video_id}")
            
            temp_dir = Path('temp_videos')
            ydl_opts = self.ydl_opts.copy()
            ydl_opts['outtmpl'] = str(temp_dir / f"{video_id}.%(ext)s")
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                ydl.extract_info(video_url, download=True)
            
            for ext in ['mp4', 'webm', 'mkv', 'avi']:
                potential_file = temp_dir / f"{video_id}.{ext}"
                if potential_file.exists():
                    logger.info(f"Video downloaded: {potential_file}")
                    return str(potential_file)
            
            raise Exception("Video file not found after download")
            
        except Exception as e:
            logger.error(f"Download error {video_id}: {e}")
            raise Exception(f"download_failed: {e}")

    def extract_frames_with_embeddings(self, video_path: str, video_id: str) -> List[Dict]:
        """Extract frames with CLIP embeddings"""
        try:
            frames_dir = Path('temp_frames') / video_id
            frames_dir.mkdir(parents=True, exist_ok=True)
            
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                raise Exception("Could not open video file")
            
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration = total_frames / fps if fps > 0 else total_frames / 30
            
            logger.info(f"Video {video_id}: {total_frames} frames, {duration:.1f}s, {fps:.1f} fps")
            
            extracted_frames = []
            frame_number = 0
            saved_count = 0
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                if frame_number % self.frame_interval == 0:
                    timestamp = frame_number / fps if fps > 0 else frame_number / 30
                    
                    frame_filename = f"frame_{saved_count:04d}.jpg"
                    frame_path = frames_dir / frame_filename
                    
                    cv2.imwrite(str(frame_path), frame, [cv2.IMWRITE_JPEG_QUALITY, 95])
                    
                    # Get CLIP embedding
                    pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                    
                    with torch.no_grad():
                        image_input = self.clip_preprocess(pil_image).unsqueeze(0).to(self.device)
                        clip_features = self.clip_model.encode_image(image_input)
                        clip_embedding = clip_features.float().cpu().numpy().flatten()
                    
                    extracted_frames.append({
                        'index': saved_count,
                        'frame_number': frame_number,
                        'timestamp': timestamp,
                        'filename': frame_filename,
                        'path': str(frame_path),
                        'embedding': clip_embedding
                    })
                    
                    saved_count += 1
                
                frame_number += 1
            
            cap.release()
            
            if not extracted_frames:
                raise Exception("Could not extract any frames")
            
            logger.info(f"Extracted {len(extracted_frames)} frames")
            self.stats['frame_extraction']['total_extractions'] += 1
            self.stats['frame_extraction']['total_frames_extracted'] += len(extracted_frames)
            
            return extracted_frames
            
        except Exception as e:
            logger.error(f"Frame extraction error: {e}")
            raise Exception(f"frame_extraction_failed: {e}")

    def get_or_extract_frames(self, video_id: str) -> Tuple[List[Dict], str]:
        """FORCED extraction of new frames for all videos"""
        try:
            # FORCE extraction of new frames for EVERY video
            logger.info(f"FORCEFULLY extracting new frames for {video_id} (ignoring cloud)")
            
            # Download video
            video_path = self.download_video(video_id)
            
            # Extract frames
            frames = self.extract_frames_with_embeddings(video_path, video_id)
            
            # Upload to cloud (OVERWRITE old ones)
            try:
                cloud_path = self.upload_frames_to_cloud(frames, video_id)
                logger.info(f"New frames uploaded to cloud: {cloud_path}")
            except Exception as cloud_error:
                logger.warning(f"Cloud unavailable, continuing locally: {cloud_error}")
                cloud_path = f"local_only/{video_id}/"
                # DON'T THROW EXCEPTION, continue working
            
            # Clean up video
            try:
                os.remove(video_path)
            except Exception:
                pass
            
            return frames, cloud_path
            
        except Exception as e:
            logger.error(f"Error getting frames for {video_id}: {e}")
            raise

    def find_optimal_clusters(self, embeddings: np.ndarray, video_id: str) -> int:
        """Find optimal number of clusters"""
        try:
            n_samples = len(embeddings)
            logger.info(f"Finding optimal clusters for {video_id} ({n_samples} frames)")
            
            max_k = min(self.max_clusters, n_samples - 1, self.max_frames)
            min_k = min(self.min_clusters, max_k)
            
            if n_samples < 4:
                logger.info(f"Too few frames ({n_samples}), using 1 cluster")
                return 1
            
            if max_k <= min_k:
                logger.info(f"Limited cluster range, using {min_k}")
                return min_k
            
            best_score = -1
            best_k = min_k
            scores = {}
            
            for k in range(min_k, max_k + 1):
                try:
                    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
                    cluster_labels = kmeans.fit_predict(embeddings)
                    
                    unique_labels = np.unique(cluster_labels)
                    if len(unique_labels) != k:
                        logger.warning(f"k={k}: empty clusters")
                        continue
                    
                    score = silhouette_score(embeddings, cluster_labels)
                    scores[k] = score
                    
                    logger.info(f"k={k}: silhouette={score:.3f}")
                    
                    if score > best_score:
                        best_score = score
                        best_k = k
                        
                except Exception as e:
                    logger.warning(f"Error for k={k}: {e}")
                    continue
            
            if best_score == -1:
                logger.warning("Could not compute silhouette score, using heuristic")
                if n_samples <= 10:
                    best_k = 2
                elif n_samples <= 50:
                    best_k = 3
                elif n_samples <= 100:
                    best_k = 4
                else:
                    best_k = 5
            
            logger.info(f"Selected {best_k} clusters for {video_id} (score: {best_score:.3f})")
            return best_k
            
        except Exception as e:
            logger.error(f"Cluster search error: {e}")
            if len(embeddings) <= 10:
                return 2
            elif len(embeddings) <= 50:
                return 3
            else:
                return 4

    def adaptive_frame_selection(self, frames: List[Dict], question_embedding: np.ndarray, video_id: str) -> List[Dict]:
        """Adaptive frame selection considering proximity to question"""
        try:
            logger.info(f"Adaptive selection from {len(frames)} frames for {video_id}...")
            
            if len(frames) <= self.max_frames:
                logger.info("Few frames, returning all")
                for i, frame in enumerate(frames):
                    frame['selection_order'] = i
                    frame['cluster_id'] = 0
                    frame['distance_to_question'] = 0.0
                return frames
            
            frame_embeddings = np.array([frame['embedding'] for frame in frames])
            
            optimal_k = self.find_optimal_clusters(frame_embeddings, video_id)
            
            logger.info(f"Clustering with k={optimal_k}...")
            kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
            cluster_labels = kmeans.fit_predict(frame_embeddings)
            
            clusters = defaultdict(list)
            for i, label in enumerate(cluster_labels):
                clusters[label].append(frames[i])
            
            logger.info(f"Created {len(clusters)} clusters:")
            for cluster_id, cluster_frames in clusters.items():
                logger.info(f"Cluster {cluster_id}: {len(cluster_frames)} frames")
            
            frames_per_cluster = self.max_frames // len(clusters)
            remaining_frames = self.max_frames % len(clusters)
            
            selected_frames = []
            
            for cluster_id, cluster_frames in clusters.items():
                cluster_embeddings = np.array([frame['embedding'] for frame in cluster_frames])
                
                distances_to_question = cosine_distances([question_embedding], cluster_embeddings)[0]
                
                num_frames_for_cluster = frames_per_cluster
                if remaining_frames > 0:
                    num_frames_for_cluster += 1
                    remaining_frames -= 1
                
                closest_indices = np.argsort(distances_to_question)[:num_frames_for_cluster]
                
                for idx in closest_indices:
                    frame = cluster_frames[idx]
                    frame['cluster_id'] = int(cluster_id)
                    frame['distance_to_question'] = float(distances_to_question[idx])
                    selected_frames.append(frame)
                
                logger.info(f"Cluster {cluster_id}: {len(cluster_frames)} frames -> {len(closest_indices)} selected")
            
            selected_frames.sort(key=lambda x: x['timestamp'])
            
            for i, frame in enumerate(selected_frames):
                frame['selection_order'] = i
            
            logger.info(f"Adaptively selected {len(selected_frames)} frames")
            
            return selected_frames
            
        except Exception as e:
            logger.error(f"Adaptive selection error: {e}")
            logger.info("Falling back to uniform selection...")
            step = max(1, len(frames) // self.max_frames)
            fallback_frames = frames[::step][:self.max_frames]
            
            for i, frame in enumerate(fallback_frames):
                frame['selection_order'] = i
                frame['cluster_id'] = 0
                frame['distance_to_question'] = 0.0
            
            return fallback_frames

    def save_selected_frames(self, selected_frames: List[Dict], video_id: str) -> str:
        """Save selected frames locally and in cloud"""
        try:
            # Local save
            frames_dir = Path('selected_frames_adaptive') / video_id
            frames_dir.mkdir(parents=True, exist_ok=True)
            
            saved_frames = []
            
            for frame in selected_frames:
                new_filename = f"adaptive_{frame['selection_order']+1:02d}_cluster_{frame['cluster_id']}_frame_{frame['frame_number']:06d}.jpg"
                new_path = frames_dir / new_filename
                
                original_image = Image.open(frame['path'])
                
                max_size = 1024
                if original_image.width > max_size or original_image.height > max_size:
                    original_image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
                
                original_image.save(new_path, 'JPEG', quality=85, optimize=True)
                
                saved_frames.append({
                    'selection_order': int(frame['selection_order']),
                    'cluster_id': int(frame['cluster_id']),
                    'frame_number': int(frame['frame_number']),
                    'timestamp': float(frame['timestamp']),
                    'distance_to_question': float(frame['distance_to_question']),
                    'filename': new_filename,
                    'path': str(new_path)
                })
            
            # Save information locally
            info_file = frames_dir / 'adaptive_selection_info.json'
            selection_info = {
                'video_id': video_id,
                'selection_method': 'adaptive_clustering_with_question_similarity',
                'model_used': self.model_name,
                'total_selected': len(selected_frames),
                'frames': saved_frames,
                'created_at': datetime.now().isoformat()
            }
            
            with open(info_file, 'w', encoding='utf-8') as f:
                json.dump(selection_info, f, ensure_ascii=False, indent=2)
            
            # Upload to cloud (optional)
            try:
                safe_video_id = re.sub(r'^[-_]+', '', video_id)
                safe_video_id = re.sub(r'[^a-zA-Z0-9_-]', '_', safe_video_id)
                safe_video_id = safe_video_id[:50]
                
                cloud_selected_path = f"{self.cloud_selected_prefix}{safe_video_id}/"
                
                for frame_info in saved_frames:
                    cloud_key = f"{cloud_selected_path}{frame_info['filename']}"
                    self.s3_client.upload_file(
                        frame_info['path'],
                        self.bucket_name,
                        cloud_key
                    )
                
                # Upload information
                cloud_info_key = f"{cloud_selected_path}adaptive_selection_info.json"
                self.s3_client.put_object(
                    Bucket=self.bucket_name,
                    Key=cloud_info_key,
                    Body=json.dumps(selection_info, ensure_ascii=False, indent=2).encode('utf-8'),
                    ContentType='application/json'
                )
                
                logger.info(f"Selected frames also uploaded to cloud: {cloud_selected_path}")
                
            except Exception as cloud_e:
                logger.warning(f"Could not upload selected frames to cloud: {cloud_e}")
            
            logger.info(f"Saved {len(saved_frames)} optimized frames in {frames_dir}")
            
            return str(frames_dir)
            
        except Exception as e:
            logger.error(f"Error saving frames: {e}")
            return None

    def send_qwen_request(self, question: str, selected_frames: List[Dict]) -> Optional[Dict]:
        """Send request to Qwen2.5-VL with selected frames"""
        
        models_to_try = [self.model_name] + self.backup_models
        
        for model_name in models_to_try:
            try:
                logger.info(f"Trying multimodal model {model_name} with {len(selected_frames)} frames...")
                
                content = [
                    {
                        "type": "text",
                        "text": f"""Answer the following multiple choice question about the video based on these key frames:

{question}

Analyze the frames carefully and choose the most appropriate answer. The frames are selected to represent the most relevant visual content for this question. 

Respond with ONLY the letter of the correct answer (A, B, C, D, or E). Do not provide any explanation or additional text."""
                    }
                ]
                
                for i, frame in enumerate(selected_frames):
                    try:
                        with open(frame['path'], 'rb') as f:
                            import base64
                            image_data = base64.b64encode(f.read()).decode('utf-8')
                        
                        content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_data}"
                            }
                        })
                        
                        content.append({
                            "type": "text",
                            "text": f"Frame {i+1}: timestamp {frame['timestamp']:.1f}s (cluster {frame['cluster_id']})"
                        })
                        
                    except Exception as e:
                        logger.warning(f"Error loading frame {frame['path']}: {e}")
                        continue
                
                payload = {
                    "model": model_name,
                    "max_tokens": 1,
                    "temperature": 0.0,
                    "logprobs": True,
                    "top_logprobs": 5,
                    "messages": [
                        {
                            "role": "user",
                            "content": content
                        }
                    ]
                }
                
                headers = {
                    "Accept": "application/json",
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {self.FIREWORKS_API_KEY}"
                }
                
                response = requests.post(self.fireworks_url, headers=headers, 
                                       json=payload, timeout=180)
                
                if response.status_code == 200:
                    result = response.json()
                    if 'choices' in result and len(result['choices']) > 0:
                        choice = result['choices'][0]
                        
                        response_text = choice['message']['content']
                        logprobs_data = choice.get('logprobs', {})
                        
                        logger.info(f"Successful response from {model_name}")
                        logger.info(f"Response text: {response_text}")
                        
                        return {
                            'response_text': response_text,
                            'logprobs': logprobs_data,
                            'model_used': model_name
                        }
                    else:
                        logger.error(f"Unexpected response format: {result}")
                        continue
                
                elif response.status_code == 404:
                    logger.warning(f"Model {model_name} not found (404)")
                    continue
                
                elif response.status_code == 400:
                    logger.warning(f"Request format error for {model_name}: {response.text}")
                    continue
                
                else:
                    logger.warning(f"Error {response.status_code} for {model_name}: {response.text}")
                    continue
                    
            except requests.exceptions.Timeout:
                logger.warning(f"Timeout for {model_name}")
                continue
            except requests.exceptions.RequestException as e:
                logger.warning(f"HTTP error for {model_name}: {e}")
                continue
            except Exception as e:
                logger.warning(f"Error for {model_name}: {e}")
                continue
        
        logger.error("All multimodal models not working")
        raise Exception("api_request_failed: All models unavailable")

    def extract_answer_from_logprobs(self, result: Dict) -> Optional[str]:
        """Extract answer from logprobs of tokens A, B, C, D, E"""
        try:
            if not result or 'logprobs' not in result:
                logger.warning("No logprobs data")
                return None
                
            logprobs_data = result['logprobs']
            
            if 'content' in logprobs_data and logprobs_data['content']:
                content = logprobs_data['content'][0]
                
                if 'top_logprobs' in content:
                    answer_logprobs = {}
                    
                    for token_info in content['top_logprobs']:
                        token = token_info['token'].strip().upper()
                        logprob = token_info['logprob']
                        
                        if token in self.answer_choices:
                            answer_logprobs[token] = logprob
                    
                    logger.info(f"Logprobs for answer choices: {answer_logprobs}")
                    
                    if answer_logprobs:
                        best_answer = max(answer_logprobs.items(), key=lambda x: x[1])[0]
                        logger.info(f"Selected answer {best_answer} with logprob {answer_logprobs[best_answer]:.4f}")
                        return best_answer
                    
                elif 'token' in content:
                    token = content['token'].strip().upper()
                    if token in self.answer_choices:
                        logger.info(f"Direct answer: {token}")
                        return token
            
            response_text = result.get('response_text', '')
            fallback_answer = self.extract_answer_from_text(response_text)
            
            if fallback_answer:
                logger.info(f"Fallback answer from text: {fallback_answer}")
                return fallback_answer
            
            logger.warning("Could not extract answer from logprobs")
            return None
            
        except Exception as e:
            logger.error(f"Error extracting answer from logprobs: {e}")
            
            response_text = result.get('response_text', '') if result else ''
            return self.extract_answer_from_text(response_text)

    def extract_answer_from_text(self, response_text: str) -> Optional[str]:
        """Fallback answer extraction from text"""
        if not response_text:
            return None
        
        patterns = [
            r'^([A-E])$',
            r'^([A-E])\s*$',
            r'([A-E])',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, response_text.strip().upper())
            if match:
                return match.group(1)
        
        return None

    def process_single_video(self, video_id: str, category: str) -> Dict:
        """Process single video with optimized frame retrieval"""
        # Update attempt statistics
        self.stats['attempted']['total_videos'] += 1
        self.stats['attempted']['by_category'][category] += 1
        
        error_type = None
        frames_cloud_path = None
        
        try:
            logger.info(f"\n{'='*80}")
            logger.info(f"PROCESSING VIDEO: {video_id} ({category})")
            logger.info(f"{'='*80}")
            
            # Get question
            key = (video_id, category)
            if key not in self.dataset_index:
                raise Exception(f"Question not found for {video_id}")
            
            sample = self.dataset_index[key]
            conversations = sample['conversations']
            
            if not conversations or len(conversations) < 2:
                raise Exception("Incorrect conversation format")
            
            question = conversations[0]['value']
            true_answer = conversations[1]['value']
            true_letter = self.extract_answer_from_text(true_answer)
            
            if not true_letter:
                raise Exception("Could not extract correct answer")
            
            logger.info(f"Question: {question[:100]}...")
            logger.info(f"Correct answer: {true_letter}")
            
            # Get question embedding
            question_embedding = self.get_question_embedding(question)
            if question_embedding is None:
                raise Exception("Could not get question embedding")
            
            # Get frames (from cloud or extract new)
            try:
                all_frames, frames_cloud_path = self.get_or_extract_frames(video_id)
            except Exception as e:
                if "download_failed" in str(e):
                    error_type = "download_failed"
                elif "frame_extraction_failed" in str(e):
                    error_type = "frame_extraction_failed"
                elif "cloud_upload_failed" in str(e):
                    error_type = "cloud_upload_failed"
                else:
                    error_type = "other_errors"
                raise e
            
            # Adaptive frame selection
            selected_frames = self.adaptive_frame_selection(all_frames, question_embedding, video_id)
            
            if not selected_frames:
                error_type = "frame_extraction_failed"
                raise Exception("Could not select frames")
            
            # Save selected frames
            frames_dir = self.save_selected_frames(selected_frames, video_id)
            
            # Send request to Qwen with logprobs
            try:
                result = self.send_qwen_request(question, selected_frames)
            except Exception as e:
                error_type = "api_request_failed"
                raise e
            
            # Extract answer from logprobs
            try:
                predicted_letter = self.extract_answer_from_logprobs(result)
                
                if not predicted_letter:
                    error_type = "answer_extraction_failed"
                    raise Exception("Could not extract model answer")
            except Exception as e:
                error_type = "answer_extraction_failed"
                raise e
            
            # SUCCESSFUL PROCESSING
            is_correct = predicted_letter == true_letter
            
            # Update successfully processed statistics
            self.stats['successfully_processed']['total_videos'] += 1
            self.stats['successfully_processed']['by_category'][category]['total'] += 1
            
            if is_correct:
                self.stats['successfully_processed']['correct_answers'] += 1
                self.stats['successfully_processed']['by_category'][category]['correct'] += 1
            
            final_result = {
                'video_id': video_id,
                'category': category,
                'question': question,
                'true_answer': true_letter,
                'predicted_answer': predicted_letter,
                'is_correct': is_correct,
                'qwen_response': result['response_text'],
                'qwen_logprobs': result['logprobs'],
                'model_used': result['model_used'],
                'total_frames': len(all_frames),
                'selected_frames': len(selected_frames),
                'frames_dir': frames_dir,
                'frames_cloud_path': frames_cloud_path,
                'status': 'success',
                'selection_details': [
                    {
                        'order': int(f['selection_order']),
                        'cluster': int(f['cluster_id']),
                        'frame_num': int(f['frame_number']),
                        'timestamp': float(f['timestamp']),
                        'distance_to_question': float(f['distance_to_question'])
                    }
                    for f in selected_frames
                ]
            }
            
            logger.info(f"SUCCESS: {predicted_letter} vs {true_letter} {'CORRECT' if is_correct else 'WRONG'}")
            logger.info(f"Selected {len(selected_frames)} frames from {len(all_frames)}")
            logger.info(f"Frames saved in cloud: {frames_cloud_path}")
            
            # Clean up temporary files
            try:
                import shutil
                temp_frames_dir = Path('temp_frames') / video_id
                if temp_frames_dir.exists():
                    shutil.rmtree(temp_frames_dir)
                
                downloaded_frames_dir = Path('downloaded_frames') / video_id
                if downloaded_frames_dir.exists():
                    shutil.rmtree(downloaded_frames_dir)
                    
            except Exception as cleanup_error:
                logger.warning(f"Cleanup error: {cleanup_error}")
            
            return final_result
            
        except Exception as e:
            logger.error(f"ERROR processing video {video_id}: {e}")
            
            # Classify error
            if error_type is None:
                if "download_failed" in str(e):
                    error_type = "download_failed"
                elif "frame_extraction_failed" in str(e):
                    error_type = "frame_extraction_failed"
                elif "api_request_failed" in str(e):
                    error_type = "api_request_failed"
                elif "answer_extraction_failed" in str(e):
                    error_type = "answer_extraction_failed"
                elif "cloud_upload_failed" in str(e):
                    error_type = "cloud_upload_failed"
                else:
                    error_type = "other_errors"
            
            # Update error statistics
            self.stats['errors'][error_type] += 1
            self.stats['errors']['by_category'][category][error_type] += 1
            
            return {
                'video_id': video_id,
                'category': category,
                'error': str(e),
                'error_type': error_type,
                'frames_cloud_path': frames_cloud_path,
                'status': 'failed'
            }

    def run_full_evaluation(self, max_videos_per_category: int = None):
        """Run full evaluation on all videos"""
        logger.info(f"\nOPTIMIZED EVALUATION WITH FIXED CLOUD STORAGE")
        
        total_videos = 0
        for category, videos in self.available_videos.items():
            if max_videos_per_category:
                total_videos += min(len(videos), max_videos_per_category)
            else:
                total_videos += len(videos)
        
        estimated_time_hours = total_videos * 1.2 / 60
        estimated_cost = total_videos * 0.05
        
        logger.info(f"EXPERIMENT ESTIMATE:")
        logger.info(f"Total videos: {total_videos}")
        logger.info(f"Time: ~{estimated_time_hours:.1f} hours (forced extraction of all frames)")
        logger.info(f"Cost: ~${estimated_cost:.2f}")
        logger.info(f"Frames will be saved in cloud: {self.cloud_frames_prefix}")
        logger.info(f"Selected frames: {self.cloud_selected_prefix}")
        logger.info(f"MODE: Forced extraction of new frames for ALL videos")
        
        confirm = input("\nStart forced frame extraction for all videos? (y/N): ")
        if confirm.lower() != 'y':
            logger.info("Cancelled by user")
            return
        
        all_results = []
        
        for category in self.categories:
            if category not in self.available_videos:
                continue
            
            videos = self.available_videos[category]
            if max_videos_per_category:
                videos = videos[:max_videos_per_category]
            
            logger.info(f"\nCATEGORY: {category} ({len(videos)} videos)")
            
            for i, video_id in enumerate(tqdm(videos, desc=f"Processing {category}")):
                logger.info(f"\nVideo {i+1}/{len(videos)}: {video_id}")
                
                result = self.process_single_video(video_id, category)
                all_results.append(result)
                
                if (i + 1) % 5 == 0:
                    processed = self.stats['successfully_processed']['total_videos']
                    correct = self.stats['successfully_processed']['correct_answers']
                    attempted = self.stats['attempted']['total_videos']
                    total_extractions = self.stats['frame_extraction']['total_extractions']
                    successful_uploads = self.stats['frame_extraction']['successful_uploads']
                    partial_uploads = self.stats['frame_extraction']['partial_uploads']
                    failed_uploads = self.stats['frame_extraction']['failed_uploads']
                    total_frames = self.stats['frame_extraction']['total_frames_extracted']
                    
                    accuracy = (correct / processed * 100) if processed > 0 else 0
                    success_rate = (processed / attempted * 100) if attempted > 0 else 0
                    
                    logger.info(f"Intermediate statistics:")
                    logger.info(f"  Attempts: {attempted}")
                    logger.info(f"  Successfully processed: {processed} ({success_rate:.1f}%)")
                    logger.info(f"  Correct answers: {correct}/{processed} ({accuracy:.1f}%)")
                    logger.info(f"  Extractions: {total_extractions}, frames: {total_frames}")
                    logger.info(f"  Cloud: successful {successful_uploads}, partial {partial_uploads}, errors {failed_uploads}")
                
                time.sleep(1)
        
        self._show_final_results(all_results)
        self._save_results(all_results)
        
        return all_results

    def _show_final_results(self, all_results: List[Dict]):
        """Show final results with optimization information"""
        total_time = datetime.now() - self.stats['start_time']
        
        attempted = self.stats['attempted']['total_videos']
        processed = self.stats['successfully_processed']['total_videos']
        correct = self.stats['successfully_processed']['correct_answers']
        
        total_extractions = self.stats['frame_extraction']['total_extractions']
        successful_uploads = self.stats['frame_extraction']['successful_uploads']
        partial_uploads = self.stats['frame_extraction']['partial_uploads']
        failed_uploads = self.stats['frame_extraction']['failed_uploads']
        total_frames = self.stats['frame_extraction']['total_frames_extracted']
        
        success_rate = (processed / attempted * 100) if attempted > 0 else 0
        accuracy = (correct / processed * 100) if processed > 0 else 0
        cloud_success_rate = (successful_uploads / (successful_uploads + partial_uploads + failed_uploads) * 100) if (successful_uploads + partial_uploads + failed_uploads) > 0 else 0
        avg_frames_per_video = (total_frames / total_extractions) if total_extractions > 0 else 0
        
        total_errors = sum(self.stats['errors'][error_type] for error_type in ['download_failed', 'frame_extraction_failed', 'api_request_failed', 'answer_extraction_failed', 'cloud_upload_failed', 'other_errors'])
        
        logger.info(f"\n{'='*80}")
        logger.info("FINAL RESULTS OF OPTIMIZED EVALUATION WITH FIXES")
        logger.info(f"{'='*80}")
        logger.info(f"Execution time: {total_time}")
        logger.info(f"")
        logger.info(f"PROCESSING STATISTICS:")
        logger.info(f"  Processing attempts: {attempted}")
        logger.info(f"  Successfully processed: {processed} ({success_rate:.1f}%)")
        logger.info(f"  Total errors: {total_errors}")
        logger.info(f"")
        logger.info(f"ACCURACY (only successfully processed):")
        logger.info(f"  Correct answers: {correct}/{processed}")
        logger.info(f"  Accuracy: {accuracy:.2f}%")
        logger.info(f"")
        logger.info(f"FRAME OPTIMIZATION:")
        logger.info(f"  Total extractions: {total_extractions}")
        logger.info(f"  Total frames extracted: {total_frames}")
        logger.info(f"  Average frames per video: {avg_frames_per_video:.1f}")
        logger.info(f"")
        logger.info(f"CLOUD STATISTICS:")
        logger.info(f"  Successfully uploaded: {successful_uploads}")
        logger.info(f"  Partially uploaded: {partial_uploads}")
        logger.info(f"  Upload errors: {failed_uploads}")
        logger.info(f"  Cloud success rate: {cloud_success_rate:.1f}%")
        logger.info(f"")
        logger.info(f"CLOUD PATHS:")
        logger.info(f"  All frames: {self.cloud_frames_prefix}")
        logger.info(f"  Selected frames: {self.cloud_selected_prefix}")
        
        logger.info(f"\nERRORS BY TYPE:")
        logger.info(f"  Download: {self.stats['errors']['download_failed']}")
        logger.info(f"  Frame extraction: {self.stats['errors']['frame_extraction_failed']}")
        logger.info(f"  API requests: {self.stats['errors']['api_request_failed']}")
        logger.info(f"  Answer extraction: {self.stats['errors']['answer_extraction_failed']}")
        logger.info(f"  Cloud upload: {self.stats['errors']['cloud_upload_failed']}")
        logger.info(f"  Other: {self.stats['errors']['other_errors']}")
        
        logger.info(f"\nRESULTS BY CATEGORY:")
        logger.info(f"{'Category':<25} {'Attempts':<8} {'Success':<8} {'Correct':<10} {'Accuracy':<10}")
        logger.info("-" * 70)
        
        for category in self.categories:
            attempted_cat = self.stats['attempted']['by_category'][category]
            if attempted_cat > 0:
                processed_cat = self.stats['successfully_processed']['by_category'][category]['total']
                correct_cat = self.stats['successfully_processed']['by_category'][category]['correct']
                
                acc = (correct_cat / processed_cat * 100) if processed_cat > 0 else 0
                
                logger.info(f"{category:<25} {attempted_cat:<8} {processed_cat:<8} {correct_cat:<10} {acc:>7.1f}%")

    def _save_results(self, all_results: List[Dict]):
        """Save results with optimization information"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        
        results_file = Path('adaptive_results') / f"fixed_optimized_evaluation_{timestamp}.json"
        
        attempted = self.stats['attempted']['total_videos']
        processed = self.stats['successfully_processed']['total_videos']
        correct = self.stats['successfully_processed']['correct_answers']
        
        final_results = {
            'experiment_info': {
                'method': 'fixed_optimized_adaptive_clustering_with_cloud_storage',
                'model': self.model_name,
                'max_frames': self.max_frames,
                'frame_interval': self.frame_interval,
                'answer_extraction_method': 'logprobs',
                'timestamp': datetime.now().isoformat(),
                'total_time': str(datetime.now() - self.stats['start_time']),
                'cloud_frames_path': self.cloud_frames_prefix,
                'cloud_selected_path': self.cloud_selected_prefix,
                'fixes_applied': [
                    'safe_file_names',
                    'retry_mechanism',
                    'fallback_to_local',
                    'improved_error_handling',
                    'progress_reporting'
                ]
            },
            'processing_stats': {
                'attempted_videos': attempted,
                'successfully_processed': processed,
                'success_rate_percent': (processed / attempted * 100) if attempted > 0 else 0,
                'total_errors': attempted - processed
            },
            'accuracy_stats': {
                'correct_answers': correct,
                'total_processed': processed,
                'accuracy_percent': (correct / processed * 100) if processed > 0 else 0
            },
            'frame_extraction_stats': dict(self.stats['frame_extraction']),
            'error_breakdown': dict(self.stats['errors']),
            'results_by_category': {
                category: {
                    'attempted': self.stats['attempted']['by_category'][category],
                    'successfully_processed': self.stats['successfully_processed']['by_category'][category]['total'],
                    'correct_answers': self.stats['successfully_processed']['by_category'][category]['correct'],
                    'accuracy_percent': (
                        self.stats['successfully_processed']['by_category'][category]['correct'] / 
                        self.stats['successfully_processed']['by_category'][category]['total'] * 100
                    ) if self.stats['successfully_processed']['by_category'][category]['total'] > 0 else 0
                }
                for category in self.categories 
                if self.stats['attempted']['by_category'][category] > 0
            },
            'detailed_results': all_results
        }
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(final_results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"Results saved: {results_file}")
        
        # Brief summary
        summary_file = Path('adaptive_results') / f"fixed_optimized_summary_{timestamp}.txt"
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("FIXED OPTIMIZED ADAPTIVE FRAME SELECTION\n")
            f.write("=" * 60 + "\n\n")
            f.write(f"PROCESSING:\n")
            f.write(f"  Attempts: {attempted}\n")
            f.write(f"  Successful: {processed} ({processed/attempted*100:.1f}%)\n")
            f.write(f"  Errors: {attempted - processed}\n\n")
            f.write(f"ACCURACY (only successfully processed):\n")
            f.write(f"  Correct: {correct}/{processed}\n")
            f.write(f"  Accuracy: {correct/processed*100:.2f}%\n\n")
            f.write(f"FRAME EXTRACTION:\n")
            f.write(f"  Total extractions: {self.stats['frame_extraction']['total_extractions']}\n")
            f.write(f"  Total frames: {self.stats['frame_extraction']['total_frames_extracted']}\n")
            f.write(f"  Successful uploads: {self.stats['frame_extraction']['successful_uploads']}\n")
            f.write(f"  Partial uploads: {self.stats['frame_extraction']['partial_uploads']}\n")
            f.write(f"  Upload errors: {self.stats['frame_extraction']['failed_uploads']}\n\n")
            f.write(f"FIXES APPLIED:\n")
            f.write(f"  Safe file names\n")
            f.write(f"  Retry mechanism (3 attempts)\n")  
            f.write(f"  Fallback to local storage\n")
            f.write(f"  Improved error handling\n")
            f.write(f"  Detailed progress logging\n\n")
            f.write(f"CLOUD PATHS:\n")
            f.write(f"  All frames: {self.cloud_frames_prefix}\n")
            f.write(f"  Selected frames: {self.cloud_selected_prefix}\n\n")
            
            f.write("Results by category:\n")
            for category in self.categories:
                if self.stats['attempted']['by_category'][category] > 0:
                    att = self.stats['attempted']['by_category'][category]
                    proc = self.stats['successfully_processed']['by_category'][category]['total']
                    corr = self.stats['successfully_processed']['by_category'][category]['correct']
                    acc = (corr / proc * 100) if proc > 0 else 0
                    f.write(f"{category}: {att} attempts -> {proc} successful -> {corr} correct ({acc:.1f}%)\n")
        
        logger.info(f"Summary saved: {summary_file}")

def main():
    """Main function"""
    print("FIXED OPTIMIZED ADAPTIVE SELECTION WITH CLOUD STORAGE")
    print("=" * 70)
    
    try:
        selector = OptimizedFrameSelector()
        
        print(f"\nAVAILABLE VIDEOS:")
        for category, videos in selector.available_videos.items():
            print(f"   {category}: {len(videos)} videos")
        
        print(f"\nUsing model: {selector.model_name}")
        print(f"Answer extraction method: logprobs of tokens A, B, C, D, E")
        print(f"\nFIXES APPLIED:")
        print(f"Safe file names (removed dashes and special chars)")
        print(f"Retry mechanism (3 attempts per file)")
        print(f"Fallback to local storage if cloud unavailable")
        print(f"Improved error handling")
        print(f"Detailed progress logging every 100 frames")
        print(f"\nOPTIMIZATIONS:")
        print(f"Frames saved in cloud: {selector.cloud_frames_prefix}")
        print(f"Reuse of already extracted frames")
        print(f"Acceleration of repeated experiments")
        print(f"Selected frames also in cloud: {selector.cloud_selected_prefix}")
        
        print("\nRun options:")
        print("1. Full evaluation on all videos")
        print("2. Test evaluation (3 videos per category)")
        print("3. One category completely")
        
        choice = input("\nSelect option (1-3): ").strip()
        
        if choice == '1':
            results = selector.run_full_evaluation()
        elif choice == '2':
            results = selector.run_full_evaluation(max_videos_per_category=3)
        elif choice == '3':
            print("\nAvailable categories:")
            for i, category in enumerate(selector.categories, 1):
                print(f"{i}. {category}")
            
            cat_choice = input("Select category (1-10): ").strip()
            try:
                cat_idx = int(cat_choice) - 1
                if 0 <= cat_idx < len(selector.categories):
                    category = selector.categories[cat_idx]
                    selector.categories = [category]
                    results = selector.run_full_evaluation()
                else:
                    print("Invalid choice")
            except ValueError:
                print("Invalid input")
        else:
            print("Invalid choice")
            return
        
        print("\nEvaluation completed!")
        print("Results saved in adaptive_results/ folder")
        print("Local selected frames in selected_frames_adaptive/ folder")
        print(f"All frames in cloud: {selector.cloud_frames_prefix}")
        print(f"Selected frames in cloud: {selector.cloud_selected_prefix}")
        
    except KeyboardInterrupt:
        print("\nInterrupted by user")
    except Exception as e:
        print(f"\nError: {e}")

if __name__ == "__main__":
    main()
